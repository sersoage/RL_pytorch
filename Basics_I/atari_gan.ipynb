{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "atari_gan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgbqwbQS2hqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "efc81dbc-df39-4a54-e41d-5b6950375146"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQcdZiY02v7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0b67eb2e-531e-4401-d4c2-84cb9efae1d0"
      },
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw9qYccB2wFo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "ca78eaec-bca7-4c8e-d594-615fd8f0e338"
      },
      "source": [
        "!pip3 install numpy==1.15.4"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.15.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/7f/9d804d2348471c67a7d8b5f84f9bc59fd1cefa148986f2b74552f8573555/numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K     |████████████████████████████████| 13.9MB 4.3MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.16.4\n",
            "    Uninstalling numpy-1.16.4:\n",
            "      Successfully uninstalled numpy-1.16.4\n",
            "Successfully installed numpy-1.15.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfkyWpou2wI3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "071020d9-d8bf-48a9-80c9-c4393936614d"
      },
      "source": [
        "!pip3 install atari-py==0.1.6"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting atari-py==0.1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/cc/aabbe1580df0f9b22851e210d5e35e3faa305d10a8783997fb8e79239dbc/atari_py-0.1.6-py3-none-manylinux1_x86_64.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from atari-py==0.1.6) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from atari-py==0.1.6) (1.15.4)\n",
            "Installing collected packages: atari-py\n",
            "  Found existing installation: atari-py 0.1.15\n",
            "    Uninstalling atari-py-0.1.15:\n",
            "      Successfully uninstalled atari-py-0.1.15\n",
            "Successfully installed atari-py-0.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0BJgbpS2wL6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2673
        },
        "outputId": "148d76f6-35c7-4163-c91b-607dca176e76"
      },
      "source": [
        "!pip3 install gym==0.10.9\n",
        "!pip3 install ptan==0.3\n",
        "!pip3 install opencv-python==3.4.3.18\n",
        "!pip3 install scipy==1.1.0\n",
        "!pip3 install torch==0.4.1\n",
        "!pip3 install torchvision==0.2.1\n",
        "!pip3 install tensorboard-pytorch==0.7.1\n",
        "!pip3 install tensorflow==1.12.0\n",
        "!pip3 install tensorboard==1.12.0\n",
        "!pip3 install pybullet==2.3.6\n",
        "!pip3 install matplotlib==3.0.2\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gym==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/22/4ff09745ade385ffe707fb5f053548f0f6a6e7d5e98a2b9d6c07f5b931a7/gym-0.10.9.tar.gz (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym==0.10.9) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym==0.10.9) (1.15.4)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.10.9) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym==0.10.9) (1.12.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.10.9) (1.3.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.10.9) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.10.9) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.10.9) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.10.9) (2019.3.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym==0.10.9) (0.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/3a/0e/b86dee98876bb56cdb482cc1f72201035e46d1baf69d10d028\n",
            "Successfully built gym\n",
            "Installing collected packages: gym\n",
            "  Found existing installation: gym 0.10.11\n",
            "    Uninstalling gym-0.10.11:\n",
            "      Successfully uninstalled gym-0.10.11\n",
            "Successfully installed gym-0.10.9\n",
            "Collecting ptan==0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/14/52/2aee2e968acab9cd268278baaf2934870b6a87032fef1f6d1bc390d9db40/ptan-0.3-py3-none-any.whl\n",
            "Installing collected packages: ptan\n",
            "Successfully installed ptan-0.3\n",
            "Collecting opencv-python==3.4.3.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/7f/c836c44ab30074a8486e30f8ea6adc8e6ac02332851ab6cc069e2ac35b84/opencv_python-3.4.3.18-cp36-cp36m-manylinux1_x86_64.whl (25.0MB)\n",
            "\u001b[K     |████████████████████████████████| 25.0MB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==3.4.3.18) (1.15.4)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python\n",
            "  Found existing installation: opencv-python 3.4.5.20\n",
            "    Uninstalling opencv-python-3.4.5.20:\n",
            "      Successfully uninstalled opencv-python-3.4.5.20\n",
            "Successfully installed opencv-python-3.4.3.18\n",
            "Collecting scipy==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.15.4)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "  Found existing installation: scipy 1.3.0\n",
            "    Uninstalling scipy-1.3.0:\n",
            "      Successfully uninstalled scipy-1.3.0\n",
            "Successfully installed scipy-1.1.0\n",
            "Collecting torch==0.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K     |████████████████████████████████| 519.5MB 30kB/s \n",
            "\u001b[31mERROR: torchvision 0.3.0 has requirement torch>=1.1.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.53.post2 has requirement torch>=1.0.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.1.0\n",
            "    Uninstalling torch-1.1.0:\n",
            "      Successfully uninstalled torch-1.1.0\n",
            "Successfully installed torch-0.4.1\n",
            "Collecting torchvision==0.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (0.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.15.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision==0.2.1) (0.46)\n",
            "\u001b[31mERROR: fastai 1.0.53.post2 has requirement torch>=1.0.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torchvision\n",
            "  Found existing installation: torchvision 0.3.0\n",
            "    Uninstalling torchvision-0.3.0:\n",
            "      Successfully uninstalled torchvision-0.3.0\n",
            "Successfully installed torchvision-0.2.1\n",
            "Collecting tensorboard-pytorch==0.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/d6/b8540153f69a8720b2f032fe8c7504ee66c8c0bce9103c272bd67c8e8c77/tensorboard_pytorch-0.7.1-py2.py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboard-pytorch==0.7.1) (1.12.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from tensorboard-pytorch==0.7.1) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboard-pytorch==0.7.1) (1.15.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->tensorboard-pytorch==0.7.1) (41.0.1)\n",
            "Installing collected packages: tensorboard-pytorch\n",
            "Successfully installed tensorboard-pytorch-0.7.1\n",
            "Collecting tensorflow==1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n",
            "\u001b[K     |████████████████████████████████| 83.1MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.0.8)\n",
            "Collecting tensorboard<1.13.0,>=1.12.0 (from tensorflow==1.12.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 39.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.8.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.15.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.33.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (3.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12.0) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (0.15.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12.0) (41.0.1)\n",
            "Installing collected packages: tensorboard, tensorflow\n",
            "  Found existing installation: tensorboard 1.13.1\n",
            "    Uninstalling tensorboard-1.13.1:\n",
            "      Successfully uninstalled tensorboard-1.13.1\n",
            "  Found existing installation: tensorflow 1.14.0rc1\n",
            "    Uninstalling tensorflow-1.14.0rc1:\n",
            "      Successfully uninstalled tensorflow-1.14.0rc1\n",
            "Successfully installed tensorboard-1.12.2 tensorflow-1.12.0\n",
            "Collecting tensorboard==1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/d0/65fe48383146199f16dbd5999ef226b87bce63ad5cd73c840cf722637969/tensorboard-1.12.0-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.12.0) (1.15.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.12.0) (3.1.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.12.0) (0.33.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.12.0) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.12.0) (3.7.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.12.0) (0.15.4)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.12.0) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=36 in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard==1.12.0) (41.0.1)\n",
            "Installing collected packages: tensorboard\n",
            "  Found existing installation: tensorboard 1.12.2\n",
            "    Uninstalling tensorboard-1.12.2:\n",
            "      Successfully uninstalled tensorboard-1.12.2\n",
            "Successfully installed tensorboard-1.12.0\n",
            "Collecting pybullet==2.3.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/13/08442403b03304f584e6fcac2fe6d14b342d3d746426937becdb0456e751/pybullet-2.3.6.tar.gz (27.3MB)\n",
            "\u001b[K     |████████████████████████████████| 27.3MB 1.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pybullet\n",
            "  Building wheel for pybullet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/f1/d3/9db36951625f8470df9a3a55f17037f8e4577f6970d02da413\n",
            "Successfully built pybullet\n",
            "Installing collected packages: pybullet\n",
            "Successfully installed pybullet-2.3.6\n",
            "Collecting matplotlib==3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/07/16d781df15be30df4acfd536c479268f1208b2dfbc91e9ca5d92c9caf673/matplotlib-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (12.9MB)\n",
            "\u001b[K     |████████████████████████████████| 12.9MB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.2) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.2) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.2) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.2) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.2) (1.15.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.0.2) (41.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib==3.0.2) (1.12.0)\n",
            "\u001b[31mERROR: fastai 1.0.53.post2 has requirement torch>=1.0.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: matplotlib\n",
            "  Found existing installation: matplotlib 3.0.3\n",
            "    Uninstalling matplotlib-3.0.3:\n",
            "      Successfully uninstalled matplotlib-3.0.3\n",
            "Successfully installed matplotlib-3.0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w0P3L4S5XY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import argparse\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "import gym\n",
        "import gym.spaces\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "log = gym.logger\n",
        "log.set_level(gym.logger.INFO)\n",
        "\n",
        "LATENT_VECTOR_SIZE = 100\n",
        "DISCR_FILTERS = 64\n",
        "GENER_FILTERS = 64\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# dimension input image will be rescaled\n",
        "IMAGE_SIZE = 64\n",
        "\n",
        "LEARNING_RATE = 0.0001\n",
        "REPORT_EVERY_ITER = 100\n",
        "SAVE_IMAGE_EVERY_ITER = 1000\n",
        "\n",
        "\n",
        "class InputWrapper(gym.ObservationWrapper):\n",
        "    \"\"\"\n",
        "    Preprocessing of input numpy array:\n",
        "    1. resize image into predefined size\n",
        "    2. move color channel axis to a first place\n",
        "    \"\"\"\n",
        "    def __init__(self, *args):\n",
        "        super(InputWrapper, self).__init__(*args)\n",
        "        assert isinstance(self.observation_space, gym.spaces.Box)\n",
        "        old_space = self.observation_space\n",
        "        self.observation_space = gym.spaces.Box(self.observation(old_space.low), self.observation(old_space.high),\n",
        "                                                dtype=np.float32)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        # resize image\n",
        "        new_obs = cv2.resize(observation, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "        # transform (210, 160, 3) -> (3, 210, 160)\n",
        "        new_obs = np.moveaxis(new_obs, 2, 0)\n",
        "        return new_obs.astype(np.float32)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "        # this pipe converges image into the single number\n",
        "        self.conv_pipe = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape[0], out_channels=DISCR_FILTERS,\n",
        "                      kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=DISCR_FILTERS, out_channels=DISCR_FILTERS*2,\n",
        "                      kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(DISCR_FILTERS*2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=DISCR_FILTERS * 2, out_channels=DISCR_FILTERS * 4,\n",
        "                      kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(DISCR_FILTERS * 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=DISCR_FILTERS * 4, out_channels=DISCR_FILTERS * 8,\n",
        "                      kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(DISCR_FILTERS * 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=DISCR_FILTERS * 8, out_channels=1,\n",
        "                      kernel_size=4, stride=1, padding=0),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv_out = self.conv_pipe(x)\n",
        "        return conv_out.view(-1, 1).squeeze(dim=1)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, output_shape):\n",
        "        super(Generator, self).__init__()\n",
        "        # pipe deconvolves input vector into (3, 64, 64) image\n",
        "        self.pipe = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=LATENT_VECTOR_SIZE, out_channels=GENER_FILTERS * 8,\n",
        "                               kernel_size=4, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(GENER_FILTERS * 8),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels=GENER_FILTERS * 8, out_channels=GENER_FILTERS * 4,\n",
        "                               kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(GENER_FILTERS * 4),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels=GENER_FILTERS * 4, out_channels=GENER_FILTERS * 2,\n",
        "                               kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(GENER_FILTERS * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels=GENER_FILTERS * 2, out_channels=GENER_FILTERS,\n",
        "                               kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(GENER_FILTERS),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels=GENER_FILTERS, out_channels=output_shape[0],\n",
        "                               kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pipe(x)\n",
        "\n",
        "\n",
        "def iterate_batches(envs, batch_size=BATCH_SIZE):\n",
        "    batch = [e.reset() for e in envs]\n",
        "    env_gen = iter(lambda: random.choice(envs), None)\n",
        "\n",
        "    while True:\n",
        "        e = next(env_gen)\n",
        "        obs, reward, is_done, _ = e.step(e.action_space.sample())\n",
        "        if np.mean(obs) > 0.01:\n",
        "            batch.append(obs)\n",
        "        if len(batch) == batch_size:\n",
        "            # Normalising input between -1 to 1\n",
        "            batch_np = np.array(batch, dtype=np.float32) * 2.0 / 255.0 - 1.0\n",
        "            yield torch.tensor(batch_np)\n",
        "            batch.clear()\n",
        "        if is_done:\n",
        "            e.reset()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IncQekag5Xtb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9439
        },
        "outputId": "470254b3-0800-4153-b50a-ff73ce8db0ee"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "envs = [InputWrapper(gym.make(name)) for name in ('Breakout-v0', 'AirRaid-v0', 'Pong-v0')]\n",
        "input_shape = envs[0].observation_space.shape\n",
        "\n",
        "net_discr = Discriminator(input_shape=input_shape).to(device)\n",
        "net_gener = Generator(output_shape=input_shape).to(device)\n",
        "\n",
        "objective = nn.BCELoss()\n",
        "gen_optimizer = optim.Adam(params=net_gener.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
        "dis_optimizer = optim.Adam(params=net_discr.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
        "writer = SummaryWriter()\n",
        "\n",
        "gen_losses = []\n",
        "dis_losses = []\n",
        "iter_no = 0\n",
        "\n",
        "true_labels_v = torch.ones(BATCH_SIZE, dtype=torch.float32, device=device)\n",
        "fake_labels_v = torch.zeros(BATCH_SIZE, dtype=torch.float32, device=device)\n",
        "\n",
        "for batch_v in iterate_batches(envs):\n",
        "    # generate extra fake samples, input is 4D: batch, filters, x, y\n",
        "    gen_input_v = torch.FloatTensor(BATCH_SIZE, LATENT_VECTOR_SIZE, 1, 1).normal_(0, 1).to(device)\n",
        "    batch_v = batch_v.to(device)\n",
        "    gen_output_v = net_gener(gen_input_v)\n",
        "\n",
        "        # train discriminator\n",
        "    dis_optimizer.zero_grad()\n",
        "    dis_output_true_v = net_discr(batch_v)\n",
        "    dis_output_fake_v = net_discr(gen_output_v.detach())\n",
        "    dis_loss = objective(dis_output_true_v, true_labels_v) + objective(dis_output_fake_v, fake_labels_v)\n",
        "    dis_loss.backward()\n",
        "    dis_optimizer.step()\n",
        "    dis_losses.append(dis_loss.item())\n",
        "\n",
        "    # train generator\n",
        "    gen_optimizer.zero_grad()\n",
        "    dis_output_v = net_discr(gen_output_v)\n",
        "    gen_loss_v = objective(dis_output_v, true_labels_v)\n",
        "    gen_loss_v.backward()\n",
        "    gen_optimizer.step()\n",
        "    gen_losses.append(gen_loss_v.item())\n",
        "\n",
        "    iter_no += 1\n",
        "    if iter_no % REPORT_EVERY_ITER == 0:\n",
        "        log.info(\"Iter %d: gen_loss=%.3e, dis_loss=%.3e\", iter_no, np.mean(gen_losses), np.mean(dis_losses))\n",
        "        writer.add_scalar(\"gen_loss\", np.mean(gen_losses), iter_no)\n",
        "        writer.add_scalar(\"dis_loss\", np.mean(dis_losses), iter_no)\n",
        "        gen_losses = []\n",
        "        dis_losses = []\n",
        "    if iter_no % SAVE_IMAGE_EVERY_ITER == 0:\n",
        "        writer.add_image(\"fake\", vutils.make_grid(gen_output_v.data[:64], normalize=True), iter_no)\n",
        "        writer.add_image(\"real\", vutils.make_grid(batch_v.data[:64], normalize=True), iter_no)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Making new env: Breakout-v0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
            "  result = entry_point.load(False)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO: Making new env: AirRaid-v0\n",
            "INFO: Making new env: Pong-v0\n",
            "INFO: Iter 100: gen_loss=4.380e+00, dis_loss=1.019e-01\n",
            "INFO: Iter 200: gen_loss=6.089e+00, dis_loss=8.054e-03\n",
            "INFO: Iter 300: gen_loss=6.848e+00, dis_loss=2.628e-03\n",
            "INFO: Iter 400: gen_loss=7.188e+00, dis_loss=2.518e-03\n",
            "INFO: Iter 500: gen_loss=7.644e+00, dis_loss=1.041e-03\n",
            "INFO: Iter 600: gen_loss=7.515e+00, dis_loss=1.270e-03\n",
            "INFO: Iter 700: gen_loss=6.418e+00, dis_loss=1.485e-01\n",
            "INFO: Iter 800: gen_loss=5.903e+00, dis_loss=1.134e-01\n",
            "INFO: Iter 900: gen_loss=6.895e+00, dis_loss=5.102e-02\n",
            "INFO: Iter 1000: gen_loss=5.727e+00, dis_loss=1.652e-02\n",
            "INFO: Iter 1100: gen_loss=5.552e+00, dis_loss=1.631e-01\n",
            "INFO: Iter 1200: gen_loss=5.294e+00, dis_loss=1.908e-01\n",
            "INFO: Iter 1300: gen_loss=5.384e+00, dis_loss=2.300e-01\n",
            "INFO: Iter 1400: gen_loss=4.611e+00, dis_loss=3.136e-01\n",
            "INFO: Iter 1500: gen_loss=3.855e+00, dis_loss=4.267e-01\n",
            "INFO: Iter 1600: gen_loss=3.928e+00, dis_loss=2.800e-01\n",
            "INFO: Iter 1700: gen_loss=4.612e+00, dis_loss=2.318e-01\n",
            "INFO: Iter 1800: gen_loss=4.284e+00, dis_loss=2.110e-01\n",
            "INFO: Iter 1900: gen_loss=4.447e+00, dis_loss=2.512e-01\n",
            "INFO: Iter 2000: gen_loss=5.283e+00, dis_loss=7.030e-02\n",
            "INFO: Iter 2100: gen_loss=5.715e+00, dis_loss=1.437e-01\n",
            "INFO: Iter 2200: gen_loss=6.246e+00, dis_loss=2.007e-02\n",
            "INFO: Iter 2300: gen_loss=6.790e+00, dis_loss=1.646e-02\n",
            "INFO: Iter 2400: gen_loss=5.197e+00, dis_loss=2.434e-01\n",
            "INFO: Iter 2500: gen_loss=4.282e+00, dis_loss=2.260e-01\n",
            "INFO: Iter 2600: gen_loss=4.443e+00, dis_loss=1.712e-01\n",
            "INFO: Iter 2700: gen_loss=6.399e+00, dis_loss=2.360e-02\n",
            "INFO: Iter 2800: gen_loss=5.840e+00, dis_loss=8.928e-02\n",
            "INFO: Iter 2900: gen_loss=6.048e+00, dis_loss=2.710e-02\n",
            "INFO: Iter 3000: gen_loss=6.038e+00, dis_loss=1.906e-01\n",
            "INFO: Iter 3100: gen_loss=5.390e+00, dis_loss=1.853e-02\n",
            "INFO: Iter 3200: gen_loss=5.729e+00, dis_loss=1.606e-02\n",
            "INFO: Iter 3300: gen_loss=5.123e+00, dis_loss=1.108e-01\n",
            "INFO: Iter 3400: gen_loss=5.688e+00, dis_loss=4.923e-02\n",
            "INFO: Iter 3500: gen_loss=5.286e+00, dis_loss=8.067e-02\n",
            "INFO: Iter 3600: gen_loss=5.241e+00, dis_loss=1.590e-01\n",
            "INFO: Iter 3700: gen_loss=6.665e+00, dis_loss=1.182e-02\n",
            "INFO: Iter 3800: gen_loss=6.828e+00, dis_loss=8.931e-02\n",
            "INFO: Iter 3900: gen_loss=4.760e+00, dis_loss=1.855e-01\n",
            "INFO: Iter 4000: gen_loss=5.547e+00, dis_loss=2.790e-01\n",
            "INFO: Iter 4100: gen_loss=4.252e+00, dis_loss=2.213e-01\n",
            "INFO: Iter 4200: gen_loss=5.723e+00, dis_loss=4.433e-02\n",
            "INFO: Iter 4300: gen_loss=5.704e+00, dis_loss=5.034e-02\n",
            "INFO: Iter 4400: gen_loss=6.733e+00, dis_loss=1.671e-02\n",
            "INFO: Iter 4500: gen_loss=7.486e+00, dis_loss=1.031e-02\n",
            "INFO: Iter 4600: gen_loss=7.032e+00, dis_loss=1.137e-02\n",
            "INFO: Iter 4700: gen_loss=6.566e+00, dis_loss=1.590e-01\n",
            "INFO: Iter 4800: gen_loss=4.504e+00, dis_loss=3.405e-01\n",
            "INFO: Iter 4900: gen_loss=5.789e+00, dis_loss=4.745e-02\n",
            "INFO: Iter 5000: gen_loss=4.713e+00, dis_loss=2.477e-01\n",
            "INFO: Iter 5100: gen_loss=5.968e+00, dis_loss=5.663e-02\n",
            "INFO: Iter 5200: gen_loss=5.912e+00, dis_loss=2.612e-01\n",
            "INFO: Iter 5300: gen_loss=5.613e+00, dis_loss=5.822e-02\n",
            "INFO: Iter 5400: gen_loss=6.226e+00, dis_loss=1.118e-01\n",
            "INFO: Iter 5500: gen_loss=6.185e+00, dis_loss=1.011e-01\n",
            "INFO: Iter 5600: gen_loss=6.206e+00, dis_loss=6.573e-02\n",
            "INFO: Iter 5700: gen_loss=6.656e+00, dis_loss=1.460e-02\n",
            "INFO: Iter 5800: gen_loss=7.045e+00, dis_loss=5.930e-03\n",
            "INFO: Iter 5900: gen_loss=7.549e+00, dis_loss=8.498e-03\n",
            "INFO: Iter 6000: gen_loss=7.628e+00, dis_loss=4.579e-03\n",
            "INFO: Iter 6100: gen_loss=5.251e+00, dis_loss=3.140e-01\n",
            "INFO: Iter 6200: gen_loss=6.094e+00, dis_loss=3.454e-02\n",
            "INFO: Iter 6300: gen_loss=6.802e+00, dis_loss=1.384e-01\n",
            "INFO: Iter 6400: gen_loss=6.227e+00, dis_loss=8.036e-02\n",
            "INFO: Iter 6500: gen_loss=6.402e+00, dis_loss=7.758e-02\n",
            "INFO: Iter 6600: gen_loss=6.631e+00, dis_loss=4.376e-02\n",
            "INFO: Iter 6700: gen_loss=6.896e+00, dis_loss=8.478e-02\n",
            "INFO: Iter 6800: gen_loss=5.693e+00, dis_loss=2.386e-01\n",
            "INFO: Iter 6900: gen_loss=5.989e+00, dis_loss=7.869e-02\n",
            "INFO: Iter 7000: gen_loss=6.434e+00, dis_loss=1.108e-01\n",
            "INFO: Iter 7100: gen_loss=7.011e+00, dis_loss=8.528e-03\n",
            "INFO: Iter 7200: gen_loss=7.832e+00, dis_loss=6.789e-02\n",
            "INFO: Iter 7300: gen_loss=6.698e+00, dis_loss=7.325e-02\n",
            "INFO: Iter 7400: gen_loss=6.080e+00, dis_loss=1.057e-01\n",
            "INFO: Iter 7500: gen_loss=6.806e+00, dis_loss=5.863e-02\n",
            "INFO: Iter 7600: gen_loss=7.325e+00, dis_loss=5.852e-03\n",
            "INFO: Iter 7700: gen_loss=8.013e+00, dis_loss=8.165e-03\n",
            "INFO: Iter 7800: gen_loss=6.702e+00, dis_loss=1.376e-01\n",
            "INFO: Iter 7900: gen_loss=6.263e+00, dis_loss=5.911e-03\n",
            "INFO: Iter 8000: gen_loss=5.124e+00, dis_loss=3.152e-01\n",
            "INFO: Iter 8100: gen_loss=6.552e+00, dis_loss=7.242e-02\n",
            "INFO: Iter 8200: gen_loss=7.357e+00, dis_loss=9.309e-03\n",
            "INFO: Iter 8300: gen_loss=6.578e+00, dis_loss=7.736e-02\n",
            "INFO: Iter 8400: gen_loss=6.886e+00, dis_loss=1.091e-02\n",
            "INFO: Iter 8500: gen_loss=6.629e+00, dis_loss=5.892e-02\n",
            "INFO: Iter 8600: gen_loss=8.013e+00, dis_loss=8.189e-03\n",
            "INFO: Iter 8700: gen_loss=7.694e+00, dis_loss=5.091e-03\n",
            "INFO: Iter 8800: gen_loss=8.336e+00, dis_loss=2.247e-03\n",
            "INFO: Iter 8900: gen_loss=7.645e+00, dis_loss=1.706e-02\n",
            "INFO: Iter 9000: gen_loss=7.058e+00, dis_loss=2.229e-01\n",
            "INFO: Iter 9100: gen_loss=6.114e+00, dis_loss=1.195e-01\n",
            "INFO: Iter 9200: gen_loss=6.763e+00, dis_loss=9.871e-03\n",
            "INFO: Iter 9300: gen_loss=7.028e+00, dis_loss=5.663e-03\n",
            "INFO: Iter 9400: gen_loss=7.151e+00, dis_loss=3.924e-03\n",
            "INFO: Iter 9500: gen_loss=7.087e+00, dis_loss=2.862e-03\n",
            "INFO: Iter 9600: gen_loss=5.937e+00, dis_loss=3.369e-01\n",
            "INFO: Iter 9700: gen_loss=5.612e+00, dis_loss=1.126e-01\n",
            "INFO: Iter 9800: gen_loss=5.300e+00, dis_loss=2.436e-01\n",
            "INFO: Iter 9900: gen_loss=6.252e+00, dis_loss=5.671e-02\n",
            "INFO: Iter 10000: gen_loss=7.097e+00, dis_loss=1.255e-01\n",
            "INFO: Iter 10100: gen_loss=6.682e+00, dis_loss=9.635e-03\n",
            "INFO: Iter 10200: gen_loss=7.246e+00, dis_loss=6.291e-03\n",
            "INFO: Iter 10300: gen_loss=7.570e+00, dis_loss=8.512e-03\n",
            "INFO: Iter 10400: gen_loss=5.572e+00, dis_loss=2.263e-01\n",
            "INFO: Iter 10500: gen_loss=7.076e+00, dis_loss=6.046e-02\n",
            "INFO: Iter 10600: gen_loss=8.062e+00, dis_loss=1.804e-02\n",
            "INFO: Iter 10700: gen_loss=6.466e+00, dis_loss=1.493e-01\n",
            "INFO: Iter 10800: gen_loss=5.659e+00, dis_loss=1.374e-01\n",
            "INFO: Iter 10900: gen_loss=6.447e+00, dis_loss=6.274e-02\n",
            "INFO: Iter 11000: gen_loss=6.908e+00, dis_loss=6.263e-03\n",
            "INFO: Iter 11100: gen_loss=7.797e+00, dis_loss=8.199e-03\n",
            "INFO: Iter 11200: gen_loss=7.583e+00, dis_loss=7.655e-03\n",
            "INFO: Iter 11300: gen_loss=3.650e+00, dis_loss=6.610e-01\n",
            "INFO: Iter 11400: gen_loss=4.141e+00, dis_loss=3.032e-01\n",
            "INFO: Iter 11500: gen_loss=4.598e+00, dis_loss=3.306e-01\n",
            "INFO: Iter 11600: gen_loss=5.319e+00, dis_loss=2.002e-01\n",
            "INFO: Iter 11700: gen_loss=5.277e+00, dis_loss=2.283e-01\n",
            "INFO: Iter 11800: gen_loss=5.498e+00, dis_loss=1.744e-01\n",
            "INFO: Iter 11900: gen_loss=4.546e+00, dis_loss=2.934e-01\n",
            "INFO: Iter 12000: gen_loss=4.770e+00, dis_loss=2.303e-01\n",
            "INFO: Iter 12100: gen_loss=5.039e+00, dis_loss=1.758e-01\n",
            "INFO: Iter 12200: gen_loss=5.603e+00, dis_loss=1.113e-01\n",
            "INFO: Iter 12300: gen_loss=6.153e+00, dis_loss=1.460e-01\n",
            "INFO: Iter 12400: gen_loss=6.143e+00, dis_loss=1.172e-02\n",
            "INFO: Iter 12500: gen_loss=6.218e+00, dis_loss=7.471e-03\n",
            "INFO: Iter 12600: gen_loss=6.339e+00, dis_loss=7.298e-03\n",
            "INFO: Iter 12700: gen_loss=6.223e+00, dis_loss=7.800e-03\n",
            "INFO: Iter 12800: gen_loss=5.877e+00, dis_loss=6.851e-03\n",
            "INFO: Iter 12900: gen_loss=5.079e+00, dis_loss=1.135e-02\n",
            "INFO: Iter 13000: gen_loss=5.409e+00, dis_loss=8.973e-03\n",
            "INFO: Iter 13100: gen_loss=6.589e+00, dis_loss=5.283e-03\n",
            "INFO: Iter 13200: gen_loss=7.044e+00, dis_loss=2.454e-03\n",
            "INFO: Iter 13300: gen_loss=7.098e+00, dis_loss=2.334e-03\n",
            "INFO: Iter 13400: gen_loss=7.038e+00, dis_loss=4.280e-03\n",
            "INFO: Iter 13500: gen_loss=7.337e+00, dis_loss=1.189e-03\n",
            "INFO: Iter 13600: gen_loss=7.560e+00, dis_loss=1.045e-03\n",
            "INFO: Iter 13700: gen_loss=7.860e+00, dis_loss=7.633e-04\n",
            "INFO: Iter 13800: gen_loss=7.988e+00, dis_loss=6.730e-04\n",
            "INFO: Iter 13900: gen_loss=8.023e+00, dis_loss=6.618e-04\n",
            "INFO: Iter 14000: gen_loss=8.089e+00, dis_loss=6.057e-04\n",
            "INFO: Iter 14100: gen_loss=8.314e+00, dis_loss=5.909e-04\n",
            "INFO: Iter 14200: gen_loss=8.481e+00, dis_loss=4.879e-04\n",
            "INFO: Iter 14300: gen_loss=8.508e+00, dis_loss=6.074e-04\n",
            "INFO: Iter 14400: gen_loss=8.602e+00, dis_loss=4.384e-04\n",
            "INFO: Iter 14500: gen_loss=8.530e+00, dis_loss=8.644e-04\n",
            "INFO: Iter 14600: gen_loss=8.745e+00, dis_loss=3.497e-04\n",
            "INFO: Iter 14700: gen_loss=8.890e+00, dis_loss=5.220e-04\n",
            "INFO: Iter 14800: gen_loss=8.892e+00, dis_loss=3.195e-04\n",
            "INFO: Iter 14900: gen_loss=1.026e+01, dis_loss=2.958e-03\n",
            "INFO: Iter 15000: gen_loss=9.315e+00, dis_loss=5.602e-04\n",
            "INFO: Iter 15100: gen_loss=9.129e+00, dis_loss=5.776e-04\n",
            "INFO: Iter 15200: gen_loss=9.139e+00, dis_loss=5.207e-04\n",
            "INFO: Iter 15300: gen_loss=9.047e+00, dis_loss=4.886e-04\n",
            "INFO: Iter 15400: gen_loss=9.004e+00, dis_loss=4.818e-04\n",
            "INFO: Iter 15500: gen_loss=9.150e+00, dis_loss=3.607e-04\n",
            "INFO: Iter 15600: gen_loss=9.305e+00, dis_loss=2.758e-04\n",
            "INFO: Iter 15700: gen_loss=9.412e+00, dis_loss=2.327e-04\n",
            "INFO: Iter 15800: gen_loss=9.568e+00, dis_loss=1.836e-04\n",
            "INFO: Iter 15900: gen_loss=9.612e+00, dis_loss=1.711e-04\n",
            "INFO: Iter 16000: gen_loss=9.575e+00, dis_loss=2.234e-04\n",
            "INFO: Iter 16100: gen_loss=9.587e+00, dis_loss=2.167e-04\n",
            "INFO: Iter 16200: gen_loss=9.740e+00, dis_loss=1.840e-04\n",
            "INFO: Iter 16300: gen_loss=9.948e+00, dis_loss=1.646e-04\n",
            "INFO: Iter 16400: gen_loss=1.008e+01, dis_loss=1.463e-04\n",
            "INFO: Iter 16500: gen_loss=1.025e+01, dis_loss=1.264e-04\n",
            "INFO: Iter 16600: gen_loss=1.029e+01, dis_loss=1.232e-04\n",
            "INFO: Iter 16700: gen_loss=1.026e+01, dis_loss=1.123e-04\n",
            "INFO: Iter 16800: gen_loss=1.018e+01, dis_loss=1.326e-04\n",
            "INFO: Iter 16900: gen_loss=9.963e+00, dis_loss=1.579e-04\n",
            "INFO: Iter 17000: gen_loss=1.001e+01, dis_loss=1.370e-04\n",
            "INFO: Iter 17100: gen_loss=9.987e+00, dis_loss=1.234e-04\n",
            "INFO: Iter 17200: gen_loss=1.003e+01, dis_loss=1.137e-04\n",
            "INFO: Iter 17300: gen_loss=1.004e+01, dis_loss=1.117e-04\n",
            "INFO: Iter 17400: gen_loss=1.022e+01, dis_loss=8.894e-05\n",
            "INFO: Iter 17500: gen_loss=1.038e+01, dis_loss=7.092e-05\n",
            "INFO: Iter 17600: gen_loss=1.043e+01, dis_loss=6.039e-05\n",
            "INFO: Iter 17700: gen_loss=1.060e+01, dis_loss=5.498e-05\n",
            "INFO: Iter 17800: gen_loss=1.066e+01, dis_loss=4.289e-05\n",
            "INFO: Iter 17900: gen_loss=1.071e+01, dis_loss=4.213e-05\n",
            "INFO: Iter 18000: gen_loss=1.077e+01, dis_loss=4.027e-05\n",
            "INFO: Iter 18100: gen_loss=1.089e+01, dis_loss=3.450e-05\n",
            "INFO: Iter 18200: gen_loss=1.093e+01, dis_loss=3.214e-05\n",
            "INFO: Iter 18300: gen_loss=1.039e+01, dis_loss=2.040e-04\n",
            "INFO: Iter 18400: gen_loss=9.910e+00, dis_loss=1.083e-04\n",
            "INFO: Iter 18500: gen_loss=1.036e+01, dis_loss=6.134e-05\n",
            "INFO: Iter 18600: gen_loss=1.071e+01, dis_loss=4.591e-05\n",
            "INFO: Iter 18700: gen_loss=1.084e+01, dis_loss=5.301e-05\n",
            "INFO: Iter 18800: gen_loss=1.148e+01, dis_loss=7.457e-02\n",
            "INFO: Iter 18900: gen_loss=7.571e+00, dis_loss=3.919e-03\n",
            "INFO: Iter 19000: gen_loss=8.877e+00, dis_loss=2.006e-02\n",
            "INFO: Iter 19100: gen_loss=8.127e+00, dis_loss=1.736e-02\n",
            "INFO: Iter 19200: gen_loss=7.864e+00, dis_loss=1.017e-01\n",
            "INFO: Iter 19300: gen_loss=5.748e+00, dis_loss=8.614e-02\n",
            "INFO: Iter 19400: gen_loss=6.091e+00, dis_loss=1.766e-02\n",
            "INFO: Iter 19500: gen_loss=7.297e+00, dis_loss=5.508e-03\n",
            "INFO: Iter 19600: gen_loss=8.162e+00, dis_loss=5.816e-03\n",
            "INFO: Iter 19700: gen_loss=8.453e+00, dis_loss=3.164e-03\n",
            "INFO: Iter 19800: gen_loss=7.208e+00, dis_loss=1.296e-01\n",
            "INFO: Iter 19900: gen_loss=7.583e+00, dis_loss=6.199e-03\n",
            "INFO: Iter 20000: gen_loss=7.436e+00, dis_loss=1.271e-01\n",
            "INFO: Iter 20100: gen_loss=7.280e+00, dis_loss=4.193e-02\n",
            "INFO: Iter 20200: gen_loss=6.774e+00, dis_loss=1.160e-01\n",
            "INFO: Iter 20300: gen_loss=7.518e+00, dis_loss=6.792e-03\n",
            "INFO: Iter 20400: gen_loss=7.910e+00, dis_loss=2.874e-03\n",
            "INFO: Iter 20500: gen_loss=8.677e+00, dis_loss=4.046e-03\n",
            "INFO: Iter 20600: gen_loss=9.110e+00, dis_loss=2.106e-03\n",
            "INFO: Iter 20700: gen_loss=8.014e+00, dis_loss=2.637e-01\n",
            "INFO: Iter 20800: gen_loss=5.435e+00, dis_loss=1.696e-01\n",
            "INFO: Iter 20900: gen_loss=6.623e+00, dis_loss=8.193e-03\n",
            "INFO: Iter 21000: gen_loss=7.506e+00, dis_loss=5.841e-03\n",
            "INFO: Iter 21100: gen_loss=6.820e+00, dis_loss=1.178e-01\n",
            "INFO: Iter 21200: gen_loss=6.429e+00, dis_loss=9.391e-03\n",
            "INFO: Iter 21300: gen_loss=8.070e+00, dis_loss=1.823e-01\n",
            "INFO: Iter 21400: gen_loss=3.463e+00, dis_loss=5.381e-01\n",
            "INFO: Iter 21500: gen_loss=5.469e+00, dis_loss=1.279e-01\n",
            "INFO: Iter 21600: gen_loss=6.410e+00, dis_loss=1.284e-02\n",
            "INFO: Iter 21700: gen_loss=5.805e+00, dis_loss=2.747e-01\n",
            "INFO: Iter 21800: gen_loss=5.092e+00, dis_loss=1.953e-01\n",
            "INFO: Iter 21900: gen_loss=4.722e+00, dis_loss=2.616e-01\n",
            "INFO: Iter 22000: gen_loss=5.202e+00, dis_loss=2.018e-01\n",
            "INFO: Iter 22100: gen_loss=5.153e+00, dis_loss=2.267e-01\n",
            "INFO: Iter 22200: gen_loss=6.523e+00, dis_loss=1.127e-01\n",
            "INFO: Iter 22300: gen_loss=5.774e+00, dis_loss=7.862e-02\n",
            "INFO: Iter 22400: gen_loss=6.646e+00, dis_loss=1.724e-01\n",
            "INFO: Iter 22500: gen_loss=6.414e+00, dis_loss=4.906e-02\n",
            "INFO: Iter 22600: gen_loss=5.097e+00, dis_loss=1.875e-01\n",
            "INFO: Iter 22700: gen_loss=6.824e+00, dis_loss=3.179e-02\n",
            "INFO: Iter 22800: gen_loss=6.203e+00, dis_loss=1.337e-01\n",
            "INFO: Iter 22900: gen_loss=6.892e+00, dis_loss=1.560e-02\n",
            "INFO: Iter 23000: gen_loss=6.737e+00, dis_loss=1.713e-01\n",
            "INFO: Iter 23100: gen_loss=5.274e+00, dis_loss=3.267e-01\n",
            "INFO: Iter 23200: gen_loss=5.329e+00, dis_loss=1.226e-01\n",
            "INFO: Iter 23300: gen_loss=4.297e+00, dis_loss=2.291e-01\n",
            "INFO: Iter 23400: gen_loss=6.034e+00, dis_loss=1.567e-02\n",
            "INFO: Iter 23500: gen_loss=6.417e+00, dis_loss=1.523e-01\n",
            "INFO: Iter 23600: gen_loss=6.039e+00, dis_loss=1.245e-02\n",
            "INFO: Iter 23700: gen_loss=6.930e+00, dis_loss=5.391e-03\n",
            "INFO: Iter 23800: gen_loss=7.105e+00, dis_loss=5.633e-03\n",
            "INFO: Iter 23900: gen_loss=7.830e+00, dis_loss=8.455e-03\n",
            "INFO: Iter 24000: gen_loss=3.812e+00, dis_loss=4.362e-01\n",
            "INFO: Iter 24100: gen_loss=5.222e+00, dis_loss=2.637e-01\n",
            "INFO: Iter 24200: gen_loss=5.974e+00, dis_loss=1.104e-01\n",
            "INFO: Iter 24300: gen_loss=6.424e+00, dis_loss=9.699e-02\n",
            "INFO: Iter 24400: gen_loss=6.409e+00, dis_loss=1.378e-01\n",
            "INFO: Iter 24500: gen_loss=6.362e+00, dis_loss=1.859e-01\n",
            "INFO: Iter 24600: gen_loss=5.322e+00, dis_loss=1.689e-01\n",
            "INFO: Iter 24700: gen_loss=5.386e+00, dis_loss=2.376e-01\n",
            "INFO: Iter 24800: gen_loss=5.248e+00, dis_loss=1.046e-01\n",
            "INFO: Iter 24900: gen_loss=5.571e+00, dis_loss=9.496e-02\n",
            "INFO: Iter 25000: gen_loss=6.517e+00, dis_loss=1.690e-01\n",
            "INFO: Iter 25100: gen_loss=5.873e+00, dis_loss=8.900e-02\n",
            "INFO: Iter 25200: gen_loss=5.874e+00, dis_loss=1.233e-01\n",
            "INFO: Iter 25300: gen_loss=6.232e+00, dis_loss=2.880e-02\n",
            "INFO: Iter 25400: gen_loss=5.834e+00, dis_loss=1.044e-01\n",
            "INFO: Iter 25500: gen_loss=6.721e+00, dis_loss=8.391e-02\n",
            "INFO: Iter 25600: gen_loss=5.537e+00, dis_loss=2.192e-01\n",
            "INFO: Iter 25700: gen_loss=5.868e+00, dis_loss=3.425e-02\n",
            "INFO: Iter 25800: gen_loss=6.033e+00, dis_loss=1.953e-01\n",
            "INFO: Iter 25900: gen_loss=6.622e+00, dis_loss=7.484e-02\n",
            "INFO: Iter 26000: gen_loss=5.722e+00, dis_loss=1.328e-01\n",
            "INFO: Iter 26100: gen_loss=5.677e+00, dis_loss=2.183e-01\n",
            "INFO: Iter 26200: gen_loss=5.900e+00, dis_loss=7.767e-02\n",
            "INFO: Iter 26300: gen_loss=6.058e+00, dis_loss=1.867e-01\n",
            "INFO: Iter 26400: gen_loss=6.007e+00, dis_loss=6.542e-02\n",
            "INFO: Iter 26500: gen_loss=6.351e+00, dis_loss=1.563e-02\n",
            "INFO: Iter 26600: gen_loss=6.532e+00, dis_loss=4.785e-03\n",
            "INFO: Iter 26700: gen_loss=6.450e+00, dis_loss=1.649e-01\n",
            "INFO: Iter 26800: gen_loss=6.722e+00, dis_loss=2.883e-02\n",
            "INFO: Iter 26900: gen_loss=7.214e+00, dis_loss=1.033e-01\n",
            "INFO: Iter 27000: gen_loss=6.763e+00, dis_loss=4.510e-03\n",
            "INFO: Iter 27100: gen_loss=7.079e+00, dis_loss=3.487e-03\n",
            "INFO: Iter 27200: gen_loss=7.110e+00, dis_loss=3.354e-03\n",
            "INFO: Iter 27300: gen_loss=6.195e+00, dis_loss=2.082e-01\n",
            "INFO: Iter 27400: gen_loss=5.406e+00, dis_loss=1.040e-02\n",
            "INFO: Iter 27500: gen_loss=6.772e+00, dis_loss=2.194e-02\n",
            "INFO: Iter 27600: gen_loss=6.554e+00, dis_loss=8.825e-02\n",
            "INFO: Iter 27700: gen_loss=2.811e+00, dis_loss=5.442e-01\n",
            "INFO: Iter 27800: gen_loss=4.603e+00, dis_loss=2.804e-01\n",
            "INFO: Iter 27900: gen_loss=5.580e+00, dis_loss=2.198e-01\n",
            "INFO: Iter 28000: gen_loss=4.943e+00, dis_loss=2.592e-01\n",
            "INFO: Iter 28100: gen_loss=5.000e+00, dis_loss=1.433e-01\n",
            "INFO: Iter 28200: gen_loss=6.050e+00, dis_loss=2.137e-02\n",
            "INFO: Iter 28300: gen_loss=6.460e+00, dis_loss=6.695e-02\n",
            "INFO: Iter 28400: gen_loss=5.747e+00, dis_loss=2.966e-01\n",
            "INFO: Iter 28500: gen_loss=5.616e+00, dis_loss=5.879e-02\n",
            "INFO: Iter 28600: gen_loss=4.892e+00, dis_loss=2.016e-01\n",
            "INFO: Iter 28700: gen_loss=6.219e+00, dis_loss=1.113e-01\n",
            "INFO: Iter 28800: gen_loss=5.662e+00, dis_loss=1.225e-01\n",
            "INFO: Iter 28900: gen_loss=6.085e+00, dis_loss=1.297e-01\n",
            "INFO: Iter 29000: gen_loss=5.868e+00, dis_loss=1.433e-01\n",
            "INFO: Iter 29100: gen_loss=6.125e+00, dis_loss=1.891e-01\n",
            "INFO: Iter 29200: gen_loss=6.282e+00, dis_loss=1.517e-01\n",
            "INFO: Iter 29300: gen_loss=6.242e+00, dis_loss=7.629e-02\n",
            "INFO: Iter 29400: gen_loss=7.074e+00, dis_loss=6.358e-02\n",
            "INFO: Iter 29500: gen_loss=7.232e+00, dis_loss=5.316e-02\n",
            "INFO: Iter 29600: gen_loss=6.007e+00, dis_loss=1.083e-01\n",
            "INFO: Iter 29700: gen_loss=6.675e+00, dis_loss=1.024e-01\n",
            "INFO: Iter 29800: gen_loss=5.727e+00, dis_loss=1.271e-01\n",
            "INFO: Iter 29900: gen_loss=6.354e+00, dis_loss=2.186e-01\n",
            "INFO: Iter 30000: gen_loss=6.349e+00, dis_loss=3.729e-02\n",
            "INFO: Iter 30100: gen_loss=6.250e+00, dis_loss=1.607e-01\n",
            "INFO: Iter 30200: gen_loss=5.748e+00, dis_loss=5.443e-02\n",
            "INFO: Iter 30300: gen_loss=5.635e+00, dis_loss=2.088e-01\n",
            "INFO: Iter 30400: gen_loss=6.098e+00, dis_loss=1.578e-02\n",
            "INFO: Iter 30500: gen_loss=6.221e+00, dis_loss=1.416e-01\n",
            "INFO: Iter 30600: gen_loss=6.394e+00, dis_loss=9.636e-03\n",
            "INFO: Iter 30700: gen_loss=6.787e+00, dis_loss=2.244e-02\n",
            "INFO: Iter 30800: gen_loss=6.015e+00, dis_loss=2.019e-01\n",
            "INFO: Iter 30900: gen_loss=4.825e+00, dis_loss=1.019e-01\n",
            "INFO: Iter 31000: gen_loss=7.093e+00, dis_loss=1.046e-01\n",
            "INFO: Iter 31100: gen_loss=5.951e+00, dis_loss=5.469e-02\n",
            "INFO: Iter 31200: gen_loss=5.233e+00, dis_loss=1.700e-01\n",
            "INFO: Iter 31300: gen_loss=5.759e+00, dis_loss=2.004e-01\n",
            "INFO: Iter 31400: gen_loss=5.555e+00, dis_loss=2.024e-01\n",
            "INFO: Iter 31500: gen_loss=5.234e+00, dis_loss=2.527e-01\n",
            "INFO: Iter 31600: gen_loss=5.066e+00, dis_loss=1.382e-01\n",
            "INFO: Iter 31700: gen_loss=5.896e+00, dis_loss=1.813e-02\n",
            "INFO: Iter 31800: gen_loss=6.967e+00, dis_loss=1.848e-01\n",
            "INFO: Iter 31900: gen_loss=6.199e+00, dis_loss=1.673e-01\n",
            "INFO: Iter 32000: gen_loss=5.650e+00, dis_loss=2.675e-01\n",
            "INFO: Iter 32100: gen_loss=5.034e+00, dis_loss=2.163e-01\n",
            "INFO: Iter 32200: gen_loss=5.957e+00, dis_loss=1.143e-01\n",
            "INFO: Iter 32300: gen_loss=5.928e+00, dis_loss=1.148e-01\n",
            "INFO: Iter 32400: gen_loss=6.236e+00, dis_loss=1.952e-01\n",
            "INFO: Iter 32500: gen_loss=6.321e+00, dis_loss=8.013e-02\n",
            "INFO: Iter 32600: gen_loss=6.497e+00, dis_loss=7.888e-02\n",
            "INFO: Iter 32700: gen_loss=6.267e+00, dis_loss=1.265e-01\n",
            "INFO: Iter 32800: gen_loss=5.948e+00, dis_loss=1.041e-01\n",
            "INFO: Iter 32900: gen_loss=6.301e+00, dis_loss=1.677e-01\n",
            "INFO: Iter 33000: gen_loss=6.513e+00, dis_loss=1.594e-01\n",
            "INFO: Iter 33100: gen_loss=6.937e+00, dis_loss=7.520e-02\n",
            "INFO: Iter 33200: gen_loss=6.719e+00, dis_loss=1.740e-01\n",
            "INFO: Iter 33300: gen_loss=5.111e+00, dis_loss=6.249e-02\n",
            "INFO: Iter 33400: gen_loss=6.637e+00, dis_loss=7.497e-02\n",
            "INFO: Iter 33500: gen_loss=5.825e+00, dis_loss=1.176e-01\n",
            "INFO: Iter 33600: gen_loss=6.455e+00, dis_loss=5.086e-02\n",
            "INFO: Iter 33700: gen_loss=5.829e+00, dis_loss=1.881e-01\n",
            "INFO: Iter 33800: gen_loss=6.144e+00, dis_loss=4.696e-02\n",
            "INFO: Iter 33900: gen_loss=6.470e+00, dis_loss=2.086e-01\n",
            "INFO: Iter 34000: gen_loss=6.116e+00, dis_loss=2.428e-01\n",
            "INFO: Iter 34100: gen_loss=6.332e+00, dis_loss=8.165e-02\n",
            "INFO: Iter 34200: gen_loss=6.476e+00, dis_loss=1.248e-01\n",
            "INFO: Iter 34300: gen_loss=6.172e+00, dis_loss=1.440e-01\n",
            "INFO: Iter 34400: gen_loss=6.459e+00, dis_loss=1.285e-01\n",
            "INFO: Iter 34500: gen_loss=7.012e+00, dis_loss=7.879e-02\n",
            "INFO: Iter 34600: gen_loss=6.803e+00, dis_loss=2.240e-01\n",
            "INFO: Iter 34700: gen_loss=6.490e+00, dis_loss=6.564e-02\n",
            "INFO: Iter 34800: gen_loss=6.495e+00, dis_loss=5.570e-02\n",
            "INFO: Iter 34900: gen_loss=6.631e+00, dis_loss=1.673e-01\n",
            "INFO: Iter 35000: gen_loss=6.186e+00, dis_loss=5.426e-02\n",
            "INFO: Iter 35100: gen_loss=6.728e+00, dis_loss=8.277e-02\n",
            "INFO: Iter 35200: gen_loss=6.325e+00, dis_loss=1.638e-02\n",
            "INFO: Iter 35300: gen_loss=7.026e+00, dis_loss=7.380e-02\n",
            "INFO: Iter 35400: gen_loss=6.592e+00, dis_loss=1.892e-01\n",
            "INFO: Iter 35500: gen_loss=6.474e+00, dis_loss=9.319e-02\n",
            "INFO: Iter 35600: gen_loss=6.652e+00, dis_loss=2.147e-01\n",
            "INFO: Iter 35700: gen_loss=6.416e+00, dis_loss=1.349e-01\n",
            "INFO: Iter 35800: gen_loss=6.421e+00, dis_loss=1.870e-01\n",
            "INFO: Iter 35900: gen_loss=6.860e+00, dis_loss=6.761e-02\n",
            "INFO: Iter 36000: gen_loss=7.146e+00, dis_loss=1.463e-01\n",
            "INFO: Iter 36100: gen_loss=6.933e+00, dis_loss=1.560e-01\n",
            "INFO: Iter 36200: gen_loss=6.083e+00, dis_loss=2.083e-01\n",
            "INFO: Iter 36300: gen_loss=6.552e+00, dis_loss=1.807e-01\n",
            "INFO: Iter 36400: gen_loss=6.516e+00, dis_loss=1.318e-01\n",
            "INFO: Iter 36500: gen_loss=6.539e+00, dis_loss=1.380e-01\n",
            "INFO: Iter 36600: gen_loss=6.100e+00, dis_loss=9.573e-02\n",
            "INFO: Iter 36700: gen_loss=6.733e+00, dis_loss=5.778e-02\n",
            "INFO: Iter 36800: gen_loss=6.622e+00, dis_loss=8.757e-02\n",
            "INFO: Iter 36900: gen_loss=6.949e+00, dis_loss=1.234e-01\n",
            "INFO: Iter 37000: gen_loss=6.825e+00, dis_loss=1.005e-01\n",
            "INFO: Iter 37100: gen_loss=7.265e+00, dis_loss=9.372e-02\n",
            "INFO: Iter 37200: gen_loss=6.560e+00, dis_loss=2.121e-02\n",
            "INFO: Iter 37300: gen_loss=6.592e+00, dis_loss=1.332e-01\n",
            "INFO: Iter 37400: gen_loss=6.942e+00, dis_loss=6.143e-02\n",
            "INFO: Iter 37500: gen_loss=6.585e+00, dis_loss=1.685e-01\n",
            "INFO: Iter 37600: gen_loss=6.213e+00, dis_loss=9.272e-02\n",
            "INFO: Iter 37700: gen_loss=5.855e+00, dis_loss=1.174e-01\n",
            "INFO: Iter 37800: gen_loss=5.738e+00, dis_loss=1.881e-01\n",
            "INFO: Iter 37900: gen_loss=6.648e+00, dis_loss=2.793e-02\n",
            "INFO: Iter 38000: gen_loss=6.820e+00, dis_loss=1.237e-01\n",
            "INFO: Iter 38100: gen_loss=6.587e+00, dis_loss=3.834e-02\n",
            "INFO: Iter 38200: gen_loss=5.525e+00, dis_loss=1.542e-01\n",
            "INFO: Iter 38300: gen_loss=5.697e+00, dis_loss=1.657e-02\n",
            "INFO: Iter 38400: gen_loss=7.300e+00, dis_loss=7.154e-02\n",
            "INFO: Iter 38500: gen_loss=6.509e+00, dis_loss=2.655e-01\n",
            "INFO: Iter 38600: gen_loss=6.639e+00, dis_loss=1.780e-01\n",
            "INFO: Iter 38700: gen_loss=6.884e+00, dis_loss=7.572e-02\n",
            "INFO: Iter 38800: gen_loss=6.917e+00, dis_loss=1.758e-01\n",
            "INFO: Iter 38900: gen_loss=6.099e+00, dis_loss=9.622e-02\n",
            "INFO: Iter 39000: gen_loss=6.028e+00, dis_loss=8.259e-02\n",
            "INFO: Iter 39100: gen_loss=7.341e+00, dis_loss=1.021e-01\n",
            "INFO: Iter 39200: gen_loss=6.453e+00, dis_loss=1.373e-02\n",
            "INFO: Iter 39300: gen_loss=6.800e+00, dis_loss=1.914e-02\n",
            "INFO: Iter 39400: gen_loss=7.352e+00, dis_loss=2.263e-01\n",
            "INFO: Iter 39500: gen_loss=6.720e+00, dis_loss=1.112e-01\n",
            "INFO: Iter 39600: gen_loss=7.354e+00, dis_loss=4.982e-02\n",
            "INFO: Iter 39700: gen_loss=7.019e+00, dis_loss=7.425e-02\n",
            "INFO: Iter 39800: gen_loss=7.566e+00, dis_loss=1.323e-01\n",
            "INFO: Iter 39900: gen_loss=6.803e+00, dis_loss=1.711e-01\n",
            "INFO: Iter 40000: gen_loss=6.187e+00, dis_loss=1.112e-01\n",
            "INFO: Iter 40100: gen_loss=7.324e+00, dis_loss=4.444e-02\n",
            "INFO: Iter 40200: gen_loss=7.702e+00, dis_loss=7.054e-02\n",
            "INFO: Iter 40300: gen_loss=7.517e+00, dis_loss=1.633e-02\n",
            "INFO: Iter 40400: gen_loss=7.196e+00, dis_loss=9.614e-02\n",
            "INFO: Iter 40500: gen_loss=5.600e+00, dis_loss=1.629e-01\n",
            "INFO: Iter 40600: gen_loss=6.898e+00, dis_loss=1.051e-01\n",
            "INFO: Iter 40700: gen_loss=7.160e+00, dis_loss=4.017e-02\n",
            "INFO: Iter 40800: gen_loss=6.462e+00, dis_loss=2.495e-02\n",
            "INFO: Iter 40900: gen_loss=7.697e+00, dis_loss=1.717e-01\n",
            "INFO: Iter 41000: gen_loss=6.829e+00, dis_loss=3.369e-02\n",
            "INFO: Iter 41100: gen_loss=6.573e+00, dis_loss=5.372e-03\n",
            "INFO: Iter 41200: gen_loss=5.814e+00, dis_loss=8.936e-03\n",
            "INFO: Iter 41300: gen_loss=6.153e+00, dis_loss=5.055e-03\n",
            "INFO: Iter 41400: gen_loss=6.252e+00, dis_loss=4.764e-03\n",
            "INFO: Iter 41500: gen_loss=6.228e+00, dis_loss=5.363e-03\n",
            "INFO: Iter 41600: gen_loss=6.216e+00, dis_loss=5.370e-03\n",
            "INFO: Iter 41700: gen_loss=6.087e+00, dis_loss=7.369e-03\n",
            "INFO: Iter 41800: gen_loss=7.632e+00, dis_loss=2.581e-02\n",
            "INFO: Iter 41900: gen_loss=6.549e+00, dis_loss=5.062e-03\n",
            "INFO: Iter 42000: gen_loss=7.192e+00, dis_loss=2.339e-03\n",
            "INFO: Iter 42100: gen_loss=7.823e+00, dis_loss=3.345e-03\n",
            "INFO: Iter 42200: gen_loss=9.718e+00, dis_loss=4.021e-03\n",
            "INFO: Iter 42300: gen_loss=7.959e+00, dis_loss=1.905e-03\n",
            "INFO: Iter 42400: gen_loss=8.371e+00, dis_loss=7.843e-04\n",
            "INFO: Iter 42500: gen_loss=8.204e+00, dis_loss=1.147e-03\n",
            "INFO: Iter 42600: gen_loss=8.501e+00, dis_loss=6.285e-04\n",
            "INFO: Iter 42700: gen_loss=1.090e+01, dis_loss=1.238e-02\n",
            "INFO: Iter 42800: gen_loss=9.781e+00, dis_loss=3.619e-04\n",
            "INFO: Iter 42900: gen_loss=9.188e+00, dis_loss=3.585e-04\n",
            "INFO: Iter 43000: gen_loss=8.631e+00, dis_loss=8.924e-04\n",
            "INFO: Iter 43100: gen_loss=9.129e+00, dis_loss=2.799e-04\n",
            "INFO: Iter 43200: gen_loss=9.394e+00, dis_loss=2.656e-04\n",
            "INFO: Iter 43300: gen_loss=9.274e+00, dis_loss=2.886e-04\n",
            "INFO: Iter 43400: gen_loss=9.284e+00, dis_loss=2.535e-04\n",
            "INFO: Iter 43500: gen_loss=8.839e+00, dis_loss=4.323e-04\n",
            "INFO: Iter 43600: gen_loss=6.490e+00, dis_loss=1.961e-01\n",
            "INFO: Iter 43700: gen_loss=6.804e+00, dis_loss=6.786e-03\n",
            "INFO: Iter 43800: gen_loss=8.747e+00, dis_loss=4.424e-03\n",
            "INFO: Iter 43900: gen_loss=7.733e+00, dis_loss=1.734e-03\n",
            "INFO: Iter 44000: gen_loss=7.998e+00, dis_loss=1.084e-03\n",
            "INFO: Iter 44100: gen_loss=8.234e+00, dis_loss=6.801e-04\n",
            "INFO: Iter 44200: gen_loss=8.560e+00, dis_loss=5.838e-04\n",
            "INFO: Iter 44300: gen_loss=7.628e+00, dis_loss=1.586e-01\n",
            "INFO: Iter 44400: gen_loss=6.176e+00, dis_loss=9.424e-02\n",
            "INFO: Iter 44500: gen_loss=6.406e+00, dis_loss=7.880e-03\n",
            "INFO: Iter 44600: gen_loss=7.080e+00, dis_loss=1.976e-03\n",
            "INFO: Iter 44700: gen_loss=7.650e+00, dis_loss=1.748e-03\n",
            "INFO: Iter 44800: gen_loss=7.632e+00, dis_loss=1.266e-03\n",
            "INFO: Iter 44900: gen_loss=7.982e+00, dis_loss=8.364e-04\n",
            "INFO: Iter 45000: gen_loss=8.231e+00, dis_loss=7.069e-04\n",
            "INFO: Iter 45100: gen_loss=8.301e+00, dis_loss=8.274e-04\n",
            "INFO: Iter 45200: gen_loss=8.341e+00, dis_loss=5.781e-04\n",
            "INFO: Iter 45300: gen_loss=9.908e+00, dis_loss=3.371e-02\n",
            "INFO: Iter 45400: gen_loss=9.395e+00, dis_loss=2.534e-03\n",
            "INFO: Iter 45500: gen_loss=8.406e+00, dis_loss=5.700e-04\n",
            "INFO: Iter 45600: gen_loss=8.262e+00, dis_loss=4.141e-04\n",
            "INFO: Iter 45700: gen_loss=8.047e+00, dis_loss=2.840e-03\n",
            "INFO: Iter 45800: gen_loss=7.073e+00, dis_loss=3.713e-03\n",
            "INFO: Iter 45900: gen_loss=7.100e+00, dis_loss=1.585e-01\n",
            "INFO: Iter 46000: gen_loss=6.258e+00, dis_loss=5.051e-02\n",
            "INFO: Iter 46100: gen_loss=8.325e+00, dis_loss=4.128e-03\n",
            "INFO: Iter 46200: gen_loss=7.657e+00, dis_loss=9.239e-04\n",
            "INFO: Iter 46300: gen_loss=6.644e+00, dis_loss=9.771e-02\n",
            "INFO: Iter 46400: gen_loss=5.982e+00, dis_loss=8.487e-02\n",
            "INFO: Iter 46500: gen_loss=6.498e+00, dis_loss=3.165e-03\n",
            "INFO: Iter 46600: gen_loss=6.819e+00, dis_loss=3.936e-03\n",
            "INFO: Iter 46700: gen_loss=7.348e+00, dis_loss=1.345e-03\n",
            "INFO: Iter 46800: gen_loss=7.914e+00, dis_loss=8.205e-04\n",
            "INFO: Iter 46900: gen_loss=8.164e+00, dis_loss=6.526e-04\n",
            "INFO: Iter 47000: gen_loss=8.281e+00, dis_loss=6.157e-04\n",
            "INFO: Iter 47100: gen_loss=6.903e+00, dis_loss=6.850e-03\n",
            "INFO: Iter 47200: gen_loss=7.523e+00, dis_loss=1.535e-03\n",
            "INFO: Iter 47300: gen_loss=7.940e+00, dis_loss=6.976e-03\n",
            "INFO: Iter 47400: gen_loss=7.906e+00, dis_loss=7.497e-04\n",
            "INFO: Iter 47500: gen_loss=8.284e+00, dis_loss=6.280e-04\n",
            "INFO: Iter 47600: gen_loss=8.721e+00, dis_loss=7.777e-04\n",
            "INFO: Iter 47700: gen_loss=9.167e+00, dis_loss=1.468e-03\n",
            "INFO: Iter 47800: gen_loss=9.375e+00, dis_loss=1.153e-03\n",
            "INFO: Iter 47900: gen_loss=9.807e+00, dis_loss=5.363e-04\n",
            "INFO: Iter 48000: gen_loss=9.904e+00, dis_loss=5.495e-04\n",
            "INFO: Iter 48100: gen_loss=9.991e+00, dis_loss=5.704e-04\n",
            "INFO: Iter 48200: gen_loss=7.304e+00, dis_loss=3.568e-01\n",
            "INFO: Iter 48300: gen_loss=6.360e+00, dis_loss=1.245e-01\n",
            "INFO: Iter 48400: gen_loss=6.056e+00, dis_loss=6.338e-03\n",
            "INFO: Iter 48500: gen_loss=6.859e+00, dis_loss=2.501e-03\n",
            "INFO: Iter 48600: gen_loss=5.931e+00, dis_loss=8.063e-02\n",
            "INFO: Iter 48700: gen_loss=5.994e+00, dis_loss=8.680e-02\n",
            "INFO: Iter 48800: gen_loss=6.926e+00, dis_loss=1.739e-03\n",
            "INFO: Iter 48900: gen_loss=7.454e+00, dis_loss=8.248e-04\n",
            "INFO: Iter 49000: gen_loss=7.446e+00, dis_loss=9.647e-04\n",
            "INFO: Iter 49100: gen_loss=7.624e+00, dis_loss=7.935e-04\n",
            "INFO: Iter 49200: gen_loss=7.599e+00, dis_loss=7.992e-04\n",
            "INFO: Iter 49300: gen_loss=6.928e+00, dis_loss=4.860e-03\n",
            "INFO: Iter 49400: gen_loss=7.679e+00, dis_loss=1.021e-02\n",
            "INFO: Iter 49500: gen_loss=7.902e+00, dis_loss=8.977e-04\n",
            "INFO: Iter 49600: gen_loss=7.426e+00, dis_loss=2.164e-03\n",
            "INFO: Iter 49700: gen_loss=8.159e+00, dis_loss=1.427e-03\n",
            "INFO: Iter 49800: gen_loss=8.340e+00, dis_loss=8.075e-04\n",
            "INFO: Iter 49900: gen_loss=8.535e+00, dis_loss=7.455e-04\n",
            "INFO: Iter 50000: gen_loss=7.723e+00, dis_loss=7.121e-02\n",
            "INFO: Iter 50100: gen_loss=7.593e+00, dis_loss=1.669e-03\n",
            "INFO: Iter 50200: gen_loss=7.938e+00, dis_loss=1.016e-03\n",
            "INFO: Iter 50300: gen_loss=8.274e+00, dis_loss=8.481e-04\n",
            "INFO: Iter 50400: gen_loss=8.668e+00, dis_loss=4.819e-04\n",
            "INFO: Iter 50500: gen_loss=8.848e+00, dis_loss=3.865e-04\n",
            "INFO: Iter 50600: gen_loss=8.897e+00, dis_loss=4.799e-04\n",
            "INFO: Iter 50700: gen_loss=9.022e+00, dis_loss=2.780e-04\n",
            "INFO: Iter 50800: gen_loss=9.185e+00, dis_loss=2.397e-04\n",
            "INFO: Iter 50900: gen_loss=9.175e+00, dis_loss=2.291e-04\n",
            "INFO: Iter 51000: gen_loss=9.192e+00, dis_loss=2.107e-04\n",
            "INFO: Iter 51100: gen_loss=9.230e+00, dis_loss=2.563e-04\n",
            "INFO: Iter 51200: gen_loss=9.041e+00, dis_loss=2.617e-04\n",
            "INFO: Iter 51300: gen_loss=8.200e+00, dis_loss=1.307e-03\n",
            "INFO: Iter 51400: gen_loss=9.350e+00, dis_loss=3.732e-03\n",
            "INFO: Iter 51500: gen_loss=8.515e+00, dis_loss=1.705e-01\n",
            "INFO: Iter 51600: gen_loss=6.664e+00, dis_loss=9.253e-02\n",
            "INFO: Iter 51700: gen_loss=5.753e+00, dis_loss=2.281e-01\n",
            "INFO: Iter 51800: gen_loss=7.205e+00, dis_loss=1.040e-01\n",
            "INFO: Iter 51900: gen_loss=6.100e+00, dis_loss=3.626e-02\n",
            "INFO: Iter 52000: gen_loss=7.163e+00, dis_loss=4.785e-03\n",
            "INFO: Iter 52100: gen_loss=6.088e+00, dis_loss=1.623e-01\n",
            "INFO: Iter 52200: gen_loss=7.999e+00, dis_loss=4.700e-02\n",
            "INFO: Iter 52300: gen_loss=8.610e+00, dis_loss=1.332e-01\n",
            "INFO: Iter 52400: gen_loss=6.915e+00, dis_loss=1.356e-01\n",
            "INFO: Iter 52500: gen_loss=6.989e+00, dis_loss=7.119e-02\n",
            "INFO: Iter 52600: gen_loss=6.209e+00, dis_loss=5.392e-02\n",
            "INFO: Iter 52700: gen_loss=7.112e+00, dis_loss=1.278e-01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-bc62fc166445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mgen_input_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLATENT_VECTOR_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mbatch_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mgen_output_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_gener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_input_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# train discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-107027d74300>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mthreshold\u001b[0;34m(input, threshold, value, inplace)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT8yc-575Xo9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e739d469-6883-4af3-8842-6878a42ac4f2"
      },
      "source": [
        "ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mruns\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqP52bpn5Xk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cd runs/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDkBWyzX5XhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd runs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajkasdRbDSl-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c0cc179-91dc-4157-8911-bf8cc4ebf117"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "events.out.tfevents.1561169171.cf9606eceb8a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhwumIOtDSy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            writer.add_image(\"fake\", vutils.make_grid(gen_output_v.data[:64], normalize=True), iter_no)\n",
        "            writer.add_image(\"real\", vutils.make_grid(batch_v.data[:64], normalize=True), iter_no)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4bSufmeDTBa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54ed0b1a-12ad-4c69-dcc5-bacfe445fc78"
      },
      "source": [
        "writer"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorboardX.writer.SummaryWriter at 0x7f3b87716358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6M9Qe_qD80e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "a49592c6-f4ff-4fb1-9fb5-8ebbabef9a91"
      },
      "source": [
        "writer()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-128d9a046341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'SummaryWriter' object is not callable"
          ]
        }
      ]
    }
  ]
}